{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "GP-relax.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9mRp37Ehb8_5",
        "qB0nCE4tRmTE",
        "bvH-Ox9tRmTF",
        "XIMwHblQV3nj",
        "pqdH2qFEV7oX",
        "AsJx2BwYV_X2"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mRp37Ehb8_5"
      },
      "source": [
        "#### Prepare packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3J3kMDKRq9W",
        "outputId": "e4801c3c-2d10-47a9-a7cf-a2ab78a7e565"
      },
      "source": [
        "!pip install ase\r\n",
        "!git clone https://github.com/yilinyang1/GPR-kernel.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ase\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/36/de17e79f29e06d9a92746d0dd9ec4636487ab03f6af10e78586aae533f7a/ase-3.21.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from ase) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from ase) (1.19.5)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ase) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->ase) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->ase) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->ase) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->ase) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=2.0.0->ase) (1.15.0)\n",
            "Installing collected packages: ase\n",
            "Successfully installed ase-3.21.1\n",
            "Cloning into 'GPR-kernel'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 22 (delta 2), reused 22 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (22/22), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN0ma97VRmS_"
      },
      "source": [
        "from ase.db import connect\n",
        "import numpy as np\n",
        "from scipy.linalg import solve_triangular\n",
        "from numpy.linalg import cholesky, det\n",
        "from scipy.optimize import minimize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB0nCE4tRmTE"
      },
      "source": [
        "#### Prepare data\n",
        "\n",
        "For each config with N atoms, x is a vector of 3N (cartesian coordinates), y is a vector of 1 + 3N dimensions with energy and forces.  \n",
        "For a training set with M configurations, X is a matrix of [M, 3N], y is a vector of [M * (1+3N)]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwdVWSwTRmTE"
      },
      "source": [
        "def atoms2data(images):\n",
        "    X = []\n",
        "    y = []\n",
        "    for atoms in images:\n",
        "        entry_X = atoms.positions.flatten()\n",
        "        entry_y_nrg = atoms.get_potential_energy()\n",
        "        # negative because in kernel we deal with positive derivative\n",
        "        entry_y_frs = -1.0 * atoms.get_forces().flatten()\n",
        "        entry_y = np.concatenate([[entry_y_nrg], entry_y_frs], axis=0)\n",
        "        X.append(entry_X)\n",
        "        y.append(entry_y)\n",
        "    \n",
        "    y_new = []  # reorder y\n",
        "    n, d = len(images), 1 + len(images[0]) * 3\n",
        "    for i in range(d):\n",
        "        for j in range(n):\n",
        "            y_new.append(y[j][i])\n",
        "    return np.array(X), np.array(y_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOeIFyA0RmTF"
      },
      "source": [
        "db = connect('./GPR-kernel/acrolein-AgPd-sample.db')\n",
        "images = [entry.toatoms() for entry in db.select()]\n",
        "\n",
        "n_atoms = len(images[0])\n",
        "X_train, y_train = atoms2data(images[0:2])  # first two images as training set\n",
        "X_valid, _ = atoms2data([images[2], images[3]])  # third and forth images as test set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvH-Ox9tRmTF"
      },
      "source": [
        "#### Build GP potential\n",
        " - prior: max energies in training set and zero forces according to the paper\n",
        " - kernel between two data points\n",
        " - kernel between one test data with the training set (this is enough for this application since during relaxation, we need to predict energy and forces of configurations sequentially)\n",
        " - calculate likelihood of the training set\n",
        " - optimization of the hyperparameters based on likelihood\n",
        "\n",
        "##### Hyperparameters: (based on https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.122.156001)\n",
        " - signal noise before kernel, $\\sigma_f$, set as 1.0\n",
        " - energy data noise: $\\sigma_n^e$, optimize between [0.001, 0.01]\n",
        " - force data noise: $\\sigma_n^f$, optiomize between [0.0001, 0.001]\n",
        " - length scale: $l_m$, optimize between [0.01, $d_{path}$], $d_{path}$ is the Euclidean distance of the last NEB path (not sure the meaning of it), set as 1.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlHqi91GRmTG"
      },
      "source": [
        "# three types of kernel: energy-energy, energy-force, force-force\n",
        "def ee_kernel(x, xp, lens):\n",
        "    \"\"\"\n",
        "    x: (d, ), positions, row\n",
        "    xp: (d, ), positions, col\n",
        "    lens: (d, ), length scales\n",
        "    \"\"\"\n",
        "    inner = 0.5 * (np.square((x - xp) / lens)).sum()\n",
        "    return 1.0 * np.exp(-inner)\n",
        "\n",
        "def ef_kernel(x, xp, lens, d):\n",
        "    \"\"\"\n",
        "    x: (d, ), positions, row\n",
        "    xp: (d, ), positions, col\n",
        "    lens: (d, ), length scales\n",
        "    d: which dimension of force or cartisian coordinate\n",
        "    \"\"\"\n",
        "    pre = 1.0 * ((x[d] - xp[d])) / (lens**2)\n",
        "    inner = 0.5 * (np.square((x - xp) / lens)).sum()\n",
        "    return pre * np.exp(-inner)\n",
        "\n",
        "def fe_kernel(x, xp, lens, d):\n",
        "    \"\"\"\n",
        "    x: (d, ), positions, row\n",
        "    xp: (d, ), positions, col\n",
        "    lens: (d, ), length scales\n",
        "    d: which dimension of force or cartisian coordinate\n",
        "    \"\"\"\n",
        "    pre = -1.0 * ((x[d] - xp[d])) / (lens**2)\n",
        "    inner = 0.5 * (np.square((x - xp) / lens)).sum()\n",
        "    return pre * np.exp(-inner)\n",
        "\n",
        "def ff_kernel(x, xp, lens, d, dp):\n",
        "    \"\"\"\n",
        "    x: (d, ), positions, row\n",
        "    xp: (d, ), positions, col\n",
        "    lens: (d, ), length scales\n",
        "    d: which dimension of force or cartisian coordinate\n",
        "    dp: which dimension of force or cartisian coordinate\n",
        "    \"\"\"\n",
        "    delta = 1 if d == dp else 0\n",
        "    pre = 1.0 / (lens ** 2) * (delta - (x[d] - xp[d]) * (x[dp] - xp[dp]) / (lens ** 2))\n",
        "    inner = 0.5 * (np.square((x - xp) / lens)).sum()\n",
        "    return pre * np.exp(-inner)\n",
        "\n",
        "def kernel_train(X_train, lens):\n",
        "    \"\"\"\n",
        "    X: [m1, d], positions\n",
        "    lens: length scales\n",
        "    return: kernel matrix for the training data\n",
        "    [[K,     Kgd], \n",
        "     [Kgd^T, Kdd]]\n",
        "    K: [n, n]  for energy\n",
        "    Kgd: [n, nd]  for energy and forces\n",
        "    Kdd: [nd, nd] for forces and forces\n",
        "    \n",
        "    The forces are ordered as: [f_11, f_21, ...f_n1, ..., f_1d, f_2d, ..., fnd]\n",
        "    \"\"\"\n",
        "    n, dim = len(X_train), len(X_train[0])\n",
        "    res = np.zeros([n * (1 + dim), n * (1 + dim)])\n",
        "    \n",
        "    # fill the energy kernel matrix K\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            if i <= j:\n",
        "                res[i][j] = ee_kernel(X_train[i], X_train[j], lens)\n",
        "            else:\n",
        "                res[i][j] = res[j][i]\n",
        "    \n",
        "    # fill the energy and force kernel matrix\n",
        "    for i in range(n):\n",
        "        for j in range(n, n * (1 + dim)):\n",
        "            config_id = j % n\n",
        "            d = j // n - 1\n",
        "            res[i][j] = ef_kernel(X_train[i], X_train[config_id], lens, d)\n",
        "    \n",
        "    # fill the force and energy kernel matrix\n",
        "    for i in range(n, n * (1 + dim)):\n",
        "        for j in range(n):\n",
        "            res[i][j] = res[j][i]\n",
        "            \n",
        "    # fill the force and force kernel matrix\n",
        "    for i in range(n, n * (1 + dim)):\n",
        "        for j in range(n, n * (1 + dim)):\n",
        "            if i <= j:\n",
        "                id1, d1 = i % n, i // n - 1\n",
        "                id2, d2 = j % n, j // n - 1\n",
        "                value = ff_kernel(X_train[id1], X_train[id2], lens, d1, d2)\n",
        "                res[i][j] = value\n",
        "            else:\n",
        "                res[i][j] = res[j][i]\n",
        "    \n",
        "    return res\n",
        "\n",
        "def nll_obs(K, y, sigma_e, sigma_f, n):\n",
        "    \"\"\"\n",
        "    K: kernel matrix of the training set\n",
        "    y: observation of the training set\n",
        "    sigma_e: noise of energy\n",
        "    sigma_f: noise of forces\n",
        "    n: number of training instances\n",
        "    \"\"\"\n",
        "    diag = np.zeros_like(K)\n",
        "    for i in range(n):\n",
        "        diag[i][i] = sigma_e ** 2\n",
        "    for i in range(n, len(diag)):\n",
        "        diag[i][i] = sigma_f ** 2\n",
        "    \n",
        "    noise_K = K + diag\n",
        "    \n",
        "    # stable\n",
        "    L = cholesky(noise_K)\n",
        "    S1 = solve_triangular(L, y, lower=True)\n",
        "    S2 = solve_triangular(L.T, S1, lower=False)\n",
        "    nll = np.sum(np.log(np.diagonal(L))) + 0.5 * y.dot(S2) + 0.5 * n * np.log(2*np.pi)\n",
        "    return nll\n",
        "\n",
        "\n",
        "def train(X_train, y_train, l_max):\n",
        "    \"\"\"\n",
        "    X_train: [n, 3 * d]\n",
        "    y_train: [n * (1 + 3d)]\n",
        "    \"\"\"    \n",
        "    def obj_func(theta):\n",
        "        sigma_e, sigma_f, lens = theta[0], theta[1], theta[2]\n",
        "        kernel_matrix = kernel_train(X_train, lens)\n",
        "        return nll_obs(kernel_matrix, y_train, sigma_e, sigma_f, len(X_train))\n",
        "\n",
        "    init_sigma_e, init_sigma_f, init_lens = 0.005, 0.0005, 1.0\n",
        "    init_theta = [init_sigma_e, init_sigma_f, init_lens] \n",
        "\n",
        "    bnds = [[0.001, 0.01], [0.0001, 0.001], [0.01, l_max]]\n",
        "    res = minimize(obj_func, init_theta, bounds=bnds)\n",
        "    return res\n",
        "\n",
        "\n",
        "def predict(X_train, y_train, x_test, theta):\n",
        "    sigma_e, sigma_f, lens = theta[0], theta[1], theta[2]\n",
        "    n_train, dim = len(X_train), X_train.shape[1]\n",
        "    kernel_matrix = kernel_train(X_train, lens)\n",
        "    diag = np.zeros_like(kernel_matrix)\n",
        "    for i in range(n_train):\n",
        "        diag[i][i] = sigma_e ** 2\n",
        "    for i in range(n_train, len(diag)):\n",
        "        diag[i][i] = sigma_f ** 2\n",
        "    noise_kernel = kernel_matrix + diag\n",
        "    \n",
        "    K_test_test = kernel_train(x_test.reshape(1, -1), lens)  # [1+d, 1+d]\n",
        "    \n",
        "    # predict energy\n",
        "    K_eX = np.zeros(len(kernel_matrix[0]))\n",
        "    # fill energy-energy\n",
        "    for i in range(n_train):\n",
        "        K_eX[i] = ee_kernel(x_test, X_train[i], lens)\n",
        "    # fill energy-force\n",
        "    for i in range(n_train, n_train * (1 + dim)):\n",
        "        train_id = i % n_train\n",
        "        d = i // n_train - 1\n",
        "        K_eX[i] = ef_kernel(x_test, X_train[train_id], lens, d)\n",
        "    \n",
        "    \n",
        "    mu_nrg = K_eX @ np.linalg.inv(noise_kernel) @ y_train\n",
        "    var_nrg = K_test_test[0][0] - K_eX @ np.linalg.inv(noise_kernel) @ K_eX.T\n",
        "    \n",
        "    # predict forces\n",
        "    K_fX = np.zeros([dim, len(kernel_matrix[0])])\n",
        "    # fill force-energy\n",
        "    for i in range(dim):\n",
        "        for j in range(n_train):\n",
        "            K_fX[i][j] = fe_kernel(x_test, X_train[j], lens, i)\n",
        "    # fill force-force\n",
        "    for i in range(dim):\n",
        "        for j in range(n_train, n_train * (1 + dim)):\n",
        "            train_id = j % n_train\n",
        "            train_d = j // n_train - 1\n",
        "            K_fX[i][j] = ff_kernel(x_test, X_train[train_id], lens, i, train_d)\n",
        "    \n",
        "    mu_frs = K_fX @ np.linalg.inv(noise_kernel) @ y_train\n",
        "    var_frs = np.diag(K_test_test)[1:] - np.diag(K_fX @ np.linalg.inv(noise_kernel) @ K_fX.T)\n",
        "    \n",
        "    return mu_nrg, var_nrg, -1.0 * mu_frs.reshape(-1, 3), var_frs.reshape(-1, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrYSjIRKRmTI"
      },
      "source": [
        "def evaluate(nrg_pred, frs_pred, nrg_label, frs_label):\n",
        "    nrg_err = abs(nrg_pred - nrg_label)\n",
        "    frs_err = abs(frs_pred - frs_label)\n",
        "    return nrg_err, frs_err"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIMwHblQV3nj"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CNDP8u7RmTK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34b532ca-40fd-4ee4-d7ca-867ea4a7e89b"
      },
      "source": [
        "%%time\r\n",
        "opt_res = train(X_train, y_train, 1.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 9.64 s, sys: 5.05 s, total: 14.7 s\n",
            "Wall time: 9.14 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqdH2qFEV7oX"
      },
      "source": [
        "#### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3nfEbYfRmTK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9994234a-65ce-4498-a0d3-c2b26451a7a4"
      },
      "source": [
        "# first test sample\n",
        "x_test = X_valid[0]\n",
        "mu_nrg, var_nrg, mu_frs, var_frs = predict(X_train, y_train, x_test, opt_res.x)\n",
        "nrg_label = images[2].get_potential_energy()\n",
        "frs_label = images[2].get_forces()\n",
        "nrg_err, frs_err = evaluate(mu_nrg, mu_frs, nrg_label, frs_label)\n",
        "print(f'nrg mae: {nrg_err:.3f} eV, nrg std: {var_nrg**0.5:.3f} force mae: {frs_err.mean():.3f} eV/AA force mean std: {(var_frs**0.5).mean():.3f} eV/AA')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nrg mae: 0.019 eV, nrg std: 0.002 force mae: 0.068 eV/AA force mean std: 0.048 eV/AA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdVcEymaVXWi",
        "outputId": "295b82c5-f2c1-4b57-cac5-ab706711fe9d"
      },
      "source": [
        "# second test sample\r\n",
        "x_test = X_valid[1]\r\n",
        "mu_nrg, var_nrg, mu_frs, var_frs = predict(X_train, y_train, x_test, opt_res.x)\r\n",
        "nrg_label = images[3].get_potential_energy()\r\n",
        "frs_label = images[3].get_forces()\r\n",
        "nrg_err, frs_err = evaluate(mu_nrg, mu_frs, nrg_label, frs_label)\r\n",
        "print(f'nrg mae: {nrg_err:.3f} eV, nrg std: {var_nrg**0.5:.3f} force mae: {frs_err.mean():.3f} eV/AA force mean std: {(var_frs**0.5).mean():.3f} eV/AA')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nrg mae: 0.064 eV, nrg std: 0.003 force mae: 0.194 eV/AA force mean std: 0.073 eV/AA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDFMHrtsVnTC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsJx2BwYV_X2"
      },
      "source": [
        "#### C++ implementation\r\n",
        "\r\n",
        "When the size of the training set grows up, the training time increases (scales cubic with the number of training points). Use C++ to accelerate this process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-dJHhKlWCX1",
        "outputId": "4f0acce8-104a-44ce-e247-706d5a395e46"
      },
      "source": [
        "# build the C++ module\r\n",
        "! cd GPR-kernel/cpp_utils/ && python libkernel_builder.py\r\n",
        "! cp -r GPR-kernel/cpp_utils ./cpp_utils"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "generating ./_libkernel.cpp\n",
            "the current directory is '/content/GPR-kernel/cpp_utils'\n",
            "running build_ext\n",
            "building '_libkernel' extension\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I./ -I/usr/include/python3.7m -c _libkernel.cpp -o ./_libkernel.o\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I./ -I/usr/include/python3.7m -c kernels.cpp -o ./kernels.o\n",
            "\u001b[01m\u001b[Kkernels.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kdouble ff_kernel(double*, double*, double, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kkernels.cpp:49:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Klength\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     int \u001b[01;35m\u001b[Klength\u001b[m\u001b[K = *(&x + 1) - x;\n",
            "         \u001b[01;35m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 ./_libkernel.o ./kernels.o -o ./_libkernel.cpython-37m-x86_64-linux-gnu.so\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhoCUYrGWumP"
      },
      "source": [
        "from cpp_utils.gpr_utils_cpp import gpr_train, gpr_predict\r\n",
        "\r\n",
        "# more training data\r\n",
        "X_train, y_train = atoms2data(images[0:15])  # use 10 images as training set\r\n",
        "X_valid, _ = atoms2data([images[15], images[16]])  # two test images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxHPKOn2XpVU",
        "outputId": "91596cd7-0a46-4ba8-de8c-18a14561f1b8"
      },
      "source": [
        "%%time\r\n",
        "# python version\r\n",
        "opt_res_python = train(X_train, y_train, 1.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 6s, sys: 2.78 s, total: 3min 9s\n",
            "Wall time: 3min 6s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HA0hQITX6Xr",
        "outputId": "82d336f3-5dd0-4a6d-a604-c65bac19effe"
      },
      "source": [
        "%%time\r\n",
        "# C++ version\r\n",
        "opt_res_cpp = gpr_train(X_train, y_train, 1.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6.32 s, sys: 2.66 s, total: 8.98 s\n",
            "Wall time: 5.72 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgL0NHgtZuh4",
        "outputId": "aa5762c4-7cdb-42fd-cb59-9bc08ae425f5"
      },
      "source": [
        "opt_res_python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      fun: 14276.313689260465\n",
              " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
              "      jac: array([-5.92626748e-01, -8.68507027e+05, -8.94860732e+03])\n",
              "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
              "     nfev: 24\n",
              "      nit: 5\n",
              "   status: 0\n",
              "  success: True\n",
              "        x: array([0.0010965, 0.001    , 1.       ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKYIwAF8aIe2",
        "outputId": "edd1ddeb-8364-44b6-fb4d-b45017595955"
      },
      "source": [
        "opt_res_cpp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      fun: 14276.313689682744\n",
              " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
              "      jac: array([ 1.64654921e+00, -8.68500786e+05, -8.94872901e+03])\n",
              "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
              "     nfev: 24\n",
              "      nit: 5\n",
              "   status: 0\n",
              "  success: True\n",
              "        x: array([0.00109614, 0.001     , 1.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    }
  ]
}